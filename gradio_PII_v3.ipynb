{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "164bc945",
      "metadata": {
        "id": "164bc945"
      },
      "source": [
        "**This Gradio app version 3 updated on 14th Oct 2024.**\n",
        "\n",
        "\n",
        "Uses the Whiper Medium model ( on RTX 4070 with 8GB vram) or atleast T4 GPU on Colab\n",
        "*  Beep tone changed and beepify_segments function not used instead now using audio_to_beep.overlay\n",
        "\n",
        "*   Please change beep sound wave filepath according to your local dir in **\"Beeped_Audio_Path\": line 254**\n",
        "\n",
        "*  change the **whisper.load_model** on line 31 (medium/large)\n",
        "* Whisper version should be Nov 06, 2023 version. **pip install openai-whisper==20231106**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRHc1I7TNzMy",
        "outputId": "3367d977-7f90-46b7-faf9-524486f7f114"
      },
      "id": "sRHc1I7TNzMy",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HzTp9DsACO3R",
      "metadata": {
        "id": "HzTp9DsACO3R"
      },
      "source": [
        "**Other Notes:**\n",
        "\n",
        "*   Input audio: TEST_9.mp3,TEST_10.wav,TEST_11.mp3\n",
        "*   Spacy transformer based Models\n",
        "1.   Final_augmented_data_base_sim_0.6_trf.zip or\n",
        "2.   Final_augmented_data_base_sim_0.3_trf.zip\n",
        "* output file stored in **pii_beep_audio_uploads**\n",
        "For example, *new_1083801646TEST_11.wav* for TEST_11.mp3\n",
        "\n",
        "**Code changelog**\n",
        "1.   Minor change in whisper.transcribe function parameters on line 80\n",
        "2.   Removed the fullstop [.] or comma [.] on the transcription_text except\n",
        "     email on line 83. It improves the accuracy of the detection\n",
        "\n",
        "\n",
        "3.   The Submit button enables **only when Audio file /Model loaded**.otherwise it is disabled.\n",
        "4.   Output Beeped Audio will have Timestamp like\n",
        "    **beeped_audio_2024_10_14_02_15_21_TEST_10**.wav\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "G0ykfmgzR4Qz",
      "metadata": {
        "id": "G0ykfmgzR4Qz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4f25138-cfde-4f68-c1f6-6b3bce06b065"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-25aa244d-7e4a-7629-f082-77e5ba7a75b1)\n",
            "Python 3.10.12\n"
          ]
        }
      ],
      "source": [
        "#@markdown **GPU check and Python version check** (you typically atleast A100 GPU)\n",
        "!nvidia-smi -L\n",
        "#!nvidia-smi\n",
        "!python3 --version\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "1FYUMVyzayLI",
      "metadata": {
        "id": "1FYUMVyzayLI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c84700d-09af-424b-fd05-284e25498058"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#@markdown **Google Drive mount**\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "8uISykMPa7SS",
      "metadata": {
        "id": "8uISykMPa7SS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a72ca8ce-90f2-4368-c157-8afcf013cb6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current directory: /content/drive/MyDrive/Colab Notebooks/Pipeline/NER\n",
            "Beep Audio File path: /content/drive/MyDrive/Colab Notebooks/beep2.mp3\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/Colab Notebooks/Pipeline/NER')\n",
        "print(\"Current directory:\", os.getcwd())\n",
        "directory = '/content/drive/MyDrive/Colab Notebooks/Pipeline/NER'\n",
        "filename = '/content/drive/MyDrive/Colab Notebooks/beep2.mp3'\n",
        "BeepAudiofileName = os.path.join(directory, filename)\n",
        "print(\"Beep Audio File path:\", BeepAudiofileName)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "Tpr50MAAmKAe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26a34e3d-60ac-400b-8296-add2d189fa3b"
      },
      "id": "Tpr50MAAmKAe",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/Pipeline/NER\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "D_xFfApha_po",
      "metadata": {
        "id": "D_xFfApha_po",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1c3154a-1162-4234-ecbd-e23985e7ec78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai-whisper==20231106 in /usr/local/lib/python3.10/dist-packages (20231106)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (2.0.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (2.4.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (4.66.5)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (10.5.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (0.8.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20231106) (3.30.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20231106) (3.16.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20231106) (18.1.8)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231106) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231106) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231106) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (3.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (2024.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231106) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231106) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231106) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231106) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231106) (3.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231106) (1.3.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "python3-pip is already the newest version (22.0.2+dfsg-1ubuntu0.4).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "# ! and % command similar function. % handles well if multiple version of a library is detected in the system\n",
        "#%pip uninstall openai-whisper -y\n",
        "#%pip install gradio\n",
        "\n",
        "!pip install openai-whisper==20231106\n",
        "!sudo apt install python3-pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "DhBolyOk9ldp",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhBolyOk9ldp",
        "outputId": "6db464d8-3d1f-4ac1-cd0b-9fa8c7b22e9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20231106\n"
          ]
        }
      ],
      "source": [
        "import whisper\n",
        "print(whisper.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "AvQsChUNzcQp",
      "metadata": {
        "id": "AvQsChUNzcQp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39e4b88c-45ad-4cf4-f6b3-2babf2c661d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting silero-vad\n",
            "  Downloading silero_vad-5.1.2-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting onnxruntime>=1.16.1 (from silero-vad)\n",
            "  Downloading onnxruntime-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: torch>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from silero-vad) (2.4.1+cu121)\n",
            "Requirement already satisfied: torchaudio>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from silero-vad) (2.4.1+cu121)\n",
            "Collecting coloredlogs (from onnxruntime>=1.16.1->silero-vad)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.16.1->silero-vad) (24.3.25)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.16.1->silero-vad) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.16.1->silero-vad) (24.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.16.1->silero-vad) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.16.1->silero-vad) (1.13.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->silero-vad) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->silero-vad) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->silero-vad) (3.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->silero-vad) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->silero-vad) (2024.6.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.16.1->silero-vad)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.12.0->silero-vad) (3.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.16.1->silero-vad) (1.3.0)\n",
            "Downloading silero_vad-5.1.2-py3-none-any.whl (5.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime, silero-vad\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.19.2 silero-vad-5.1.2\n"
          ]
        }
      ],
      "source": [
        "# To avoid the WARNING:whisper_timestamped:Please install onnxruntime to use more efficiently silero VAD\n",
        "!pip install silero-vad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "AsyqNfMjO_Ih",
      "metadata": {
        "id": "AsyqNfMjO_Ih",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37db8c00-dfcf-4426-9dc9-be43166b56c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Ign:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy Release [5,713 B]\n",
            "Get:8 https://r2u.stat.illinois.edu/ubuntu jammy Release.gpg [793 B]\n",
            "Get:9 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,160 kB]\n",
            "Get:10 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,387 kB]\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,602 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,326 kB]\n",
            "Hit:14 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:15 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:16 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,449 kB]\n",
            "Get:18 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,595 kB]\n",
            "Fetched 18.8 MB in 4s (4,778 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "51 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 51 not upgraded.\n",
            "Collecting setuptools-rust\n",
            "  Downloading setuptools_rust-1.10.2-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: setuptools>=62.4 in /usr/local/lib/python3.10/dist-packages (from setuptools-rust) (71.0.4)\n",
            "Collecting semantic-version<3,>=2.8.2 (from setuptools-rust)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Downloading setuptools_rust-1.10.2-py3-none-any.whl (26 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Installing collected packages: semantic-version, setuptools-rust\n",
            "Successfully installed semantic-version-2.10.0 setuptools-rust-1.10.2\n",
            "Collecting openai\n",
            "  Downloading openai-1.51.2-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Downloading openai-1.51.2-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.7/383.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.2/325.2 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jiter, h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 jiter-0.6.1 openai-1.51.2\n",
            "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.10/dist-packages (20231106)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.0.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.4.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.66.5)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (10.5.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.8.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper) (3.30.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper) (3.16.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper) (18.1.8)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (2024.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (3.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper) (1.3.0)\n",
            "Collecting whisper-timestamped\n",
            "  Downloading whisper_timestamped-1.15.4-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.10/dist-packages (from whisper-timestamped) (3.0.11)\n",
            "Collecting dtw-python (from whisper-timestamped)\n",
            "  Downloading dtw_python-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: openai-whisper in /usr/local/lib/python3.10/dist-packages (from whisper-timestamped) (20231106)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from dtw-python->whisper-timestamped) (1.13.1)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from dtw-python->whisper-timestamped) (1.26.4)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper->whisper-timestamped) (2.0.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper->whisper-timestamped) (0.60.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper->whisper-timestamped) (2.4.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper->whisper-timestamped) (4.66.5)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper->whisper-timestamped) (10.5.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper->whisper-timestamped) (0.8.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper->whisper-timestamped) (3.30.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper->whisper-timestamped) (3.16.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper->whisper-timestamped) (18.1.8)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper->whisper-timestamped) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper->whisper-timestamped) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper->whisper-timestamped) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper->whisper-timestamped) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper->whisper-timestamped) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper->whisper-timestamped) (3.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper->whisper-timestamped) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper->whisper-timestamped) (2024.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper->whisper-timestamped) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper->whisper-timestamped) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper->whisper-timestamped) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper->whisper-timestamped) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper->whisper-timestamped) (3.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper->whisper-timestamped) (1.3.0)\n",
            "Downloading whisper_timestamped-1.15.4-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.5/53.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dtw_python-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (764 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m764.7/764.7 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dtw-python, whisper-timestamped\n",
            "Successfully installed dtw-python-1.5.3 whisper-timestamped-1.15.4\n",
            "Collecting gradio\n",
            "  Downloading gradio-5.1.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0 (from gradio)\n",
            "  Downloading fastapi-0.115.2-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==1.4.0 (from gradio)\n",
            "  Downloading gradio_client-1.4.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.2)\n",
            "Collecting huggingface-hub>=0.25.1 (from gradio)\n",
            "  Downloading huggingface_hub-0.25.2-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (10.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.9.2)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio)\n",
            "  Downloading python_multipart-0.0.12-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.6.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.5)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.31.1-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.4.0->gradio) (2024.6.1)\n",
            "Collecting websockets<13.0,>=10.0 (from gradio-client==1.4.0->gradio)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Collecting starlette<0.41.0,>=0.37.2 (from fastapi<1.0->gradio)\n",
            "  Downloading starlette-0.39.2-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.66.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.23.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.2.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.1.0-py3-none-any.whl (42.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.4.0-py3-none-any.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.8/319.8 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.2-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.7/94.7 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.25.2-py3-none-any.whl (436 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m436.6/436.6 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.12-py3-none-any.whl (23 kB)\n",
            "Downloading ruff-0.6.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.31.1-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading starlette-0.39.2-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydub, websockets, uvicorn, tomlkit, ruff, python-multipart, orjson, markupsafe, ffmpy, aiofiles, starlette, huggingface-hub, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.1\n",
            "    Uninstalling MarkupSafe-3.0.1:\n",
            "      Successfully uninstalled MarkupSafe-3.0.1\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.24.7\n",
            "    Uninstalling huggingface-hub-0.24.7:\n",
            "      Successfully uninstalled huggingface-hub-0.24.7\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.2 ffmpy-0.4.0 gradio-5.1.0 gradio-client-1.4.0 huggingface-hub-0.25.2 markupsafe-2.1.5 orjson-3.10.7 pydub-0.25.1 python-multipart-0.0.12 ruff-0.6.9 starlette-0.39.2 tomlkit-0.12.0 uvicorn-0.31.1 websockets-12.0\n",
            "Collecting gradio-rich-textbox\n",
            "  Downloading gradio_rich_textbox-0.4.2-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting gradio<5.0,>=4.0 (from gradio-rich-textbox)\n",
            "  Downloading gradio-4.44.1-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.0->gradio-rich-textbox) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.0->gradio-rich-textbox) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.0->gradio-rich-textbox) (0.115.2)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.0->gradio-rich-textbox) (0.4.0)\n",
            "Collecting gradio-client==1.3.0 (from gradio<5.0,>=4.0->gradio-rich-textbox)\n",
            "  Downloading gradio_client-1.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.0->gradio-rich-textbox) (0.27.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.0->gradio-rich-textbox) (0.25.2)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.0->gradio-rich-textbox) (6.4.5)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.0->gradio-rich-textbox) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.0->gradio-rich-textbox) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.0->gradio-rich-textbox) (3.7.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.0->gradio-rich-textbox) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.0->gradio-rich-textbox) (3.10.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.0->gradio-rich-textbox) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.0->gradio-rich-textbox) (2.2.2)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.0->gradio-rich-textbox) (10.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.0->gradio-rich-textbox) (2.9.2)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.0->gradio-rich-textbox) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.0->gradio-rich-textbox) (0.0.12)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.0->gradio-rich-textbox) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.0->gradio-rich-textbox) (0.6.9)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.0->gradio-rich-textbox) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.0->gradio-rich-textbox) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.0->gradio-rich-textbox) (0.12.5)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.0->gradio-rich-textbox) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.0->gradio-rich-textbox) (2.2.3)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.0->gradio-rich-textbox) (0.31.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.3.0->gradio<5.0,>=4.0->gradio-rich-textbox) (2024.6.1)\n",
            "Requirement already satisfied: websockets<13.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.3.0->gradio<5.0,>=4.0->gradio-rich-textbox) (12.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio<5.0,>=4.0->gradio-rich-textbox) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio<5.0,>=4.0->gradio-rich-textbox) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio<5.0,>=4.0->gradio-rich-textbox) (1.2.2)\n",
            "Requirement already satisfied: starlette<0.41.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi<1.0->gradio<5.0,>=4.0->gradio-rich-textbox) (0.39.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio<5.0,>=4.0->gradio-rich-textbox) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio<5.0,>=4.0->gradio-rich-textbox) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio<5.0,>=4.0->gradio-rich-textbox) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio<5.0,>=4.0->gradio-rich-textbox) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio<5.0,>=4.0->gradio-rich-textbox) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio<5.0,>=4.0->gradio-rich-textbox) (4.66.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio<5.0,>=4.0->gradio-rich-textbox) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio<5.0,>=4.0->gradio-rich-textbox) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio<5.0,>=4.0->gradio-rich-textbox) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio<5.0,>=4.0->gradio-rich-textbox) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio<5.0,>=4.0->gradio-rich-textbox) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio<5.0,>=4.0->gradio-rich-textbox) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio<5.0,>=4.0->gradio-rich-textbox) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio<5.0,>=4.0->gradio-rich-textbox) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio<5.0,>=4.0->gradio-rich-textbox) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio<5.0,>=4.0->gradio-rich-textbox) (2.23.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio<5.0,>=4.0->gradio-rich-textbox) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio<5.0,>=4.0->gradio-rich-textbox) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio<5.0,>=4.0->gradio-rich-textbox) (13.9.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio<5.0,>=4.0->gradio-rich-textbox) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio<5.0,>=4.0->gradio-rich-textbox) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio<5.0,>=4.0->gradio-rich-textbox) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio<5.0,>=4.0->gradio-rich-textbox) (3.4.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio<5.0,>=4.0->gradio-rich-textbox) (0.1.2)\n",
            "Downloading gradio_rich_textbox-0.4.2-py3-none-any.whl (28 kB)\n",
            "Downloading gradio-4.44.1-py3-none-any.whl (18.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.3.0-py3-none-any.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gradio-client, gradio, gradio-rich-textbox\n",
            "  Attempting uninstall: gradio-client\n",
            "    Found existing installation: gradio_client 1.4.0\n",
            "    Uninstalling gradio_client-1.4.0:\n",
            "      Successfully uninstalled gradio_client-1.4.0\n",
            "  Attempting uninstall: gradio\n",
            "    Found existing installation: gradio 5.1.0\n",
            "    Uninstalling gradio-5.1.0:\n",
            "      Successfully uninstalled gradio-5.1.0\n",
            "Successfully installed gradio-4.44.1 gradio-client-1.3.0 gradio-rich-textbox-0.4.2\n"
          ]
        }
      ],
      "source": [
        "!sudo apt update && sudo apt install ffmpeg\n",
        "!sudo pip3 install setuptools-rust\n",
        "%pip install openai\n",
        "%pip install openai-whisper\n",
        "%pip install whisper-timestamped\n",
        "%pip install gradio\n",
        "!pip install gradio-rich-textbox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "88667037",
      "metadata": {
        "id": "88667037",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03474007-13a6-4b9c-851d-a0ef1c80f47b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importing the dtw module. When using in academic works please cite:\n",
            "  T. Giorgino. Computing and Visualizing Dynamic Time Warping Alignments in R: The dtw Package.\n",
            "  J. Stat. Soft., doi:10.18637/jss.v031.i07.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import os\n",
        "import random\n",
        "import whisper_timestamped as whisper\n",
        "from pydub import AudioSegment\n",
        "import numpy as np\n",
        "import spacy\n",
        "import torch\n",
        "import threading\n",
        "import zipfile\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "from werkzeug.utils import secure_filename\n",
        "import time\n",
        "from gradio_rich_textbox import RichTextbox\n",
        "import re\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "12a198ed",
      "metadata": {
        "id": "12a198ed"
      },
      "outputs": [],
      "source": [
        "# Worker class to process the audio file and load models\n",
        "class Worker(threading.Thread):\n",
        "    def __init__(self, audio_file_path, model_directory, callback):\n",
        "        threading.Thread.__init__(self)\n",
        "        self._AudiofileName = audio_file_path\n",
        "        self._ModelDirectory = model_directory\n",
        "        #self._BeepAudiofileName = \"beep2.mp3\"\n",
        "        self._BeepAudiofileName = BeepAudiofileName\n",
        "        self.callback = callback\n",
        "\n",
        "        self._PII_text_and_Timestamp =\"\"\n",
        "        self._Transcribe_Text_With_Entities =\"\"\n",
        "        self._Metrics =\"\"\n",
        "        self._BeepedAudiofileName =\"\"\n",
        "\n",
        "        print(f\"Audio File: {self._AudiofileName}\")\n",
        "        print(f\"Model Directory: {self._ModelDirectory}\")\n",
        "        print(f\"Beep Audio File: {self._BeepAudiofileName}\")\n",
        "\n",
        "    def run(self):\n",
        "        try:\n",
        "            print(\"loading SpaCy model with custom model \",str(self._ModelDirectory))\n",
        "            # Load spaCy model from directory or a known model name\n",
        "            self.nlp = spacy.load(str(self._ModelDirectory))\n",
        "            print(\"SpaCy model loaded.\")\n",
        "\n",
        "            # Load Whisper model\n",
        "            devices = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "            print(devices)\n",
        "            time.sleep(0.2)\n",
        "            self.model = whisper.load_model(\"medium\", device=devices)\n",
        "\n",
        "            print(\"Whisper model loaded.\")\n",
        "\n",
        "            self.processData()\n",
        "            self.callback(\"callback Processing complete!\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error during processing: {str(e)}\")\n",
        "\n",
        "    def count_entities(self,entities):\n",
        "        entity_counts = {}  # Initialize an empty dictionary to store counts\n",
        "\n",
        "        for _, entity_type in entities:\n",
        "            # Increment the count for each entity type\n",
        "            entity_counts[entity_type] = entity_counts.get(entity_type, 0) + 1\n",
        "\n",
        "        return entity_counts\n",
        "\n",
        "    def colorize_entities(self, data, entities):\n",
        "        # Define color mappings (you can customize these)\n",
        "        color_map = {\n",
        "            'PERSON': 'blue',\n",
        "            'GPE': 'green',\n",
        "            'LOC': 'purple',\n",
        "            'PHONE': 'orange',\n",
        "            'EMAIL': 'blue',\n",
        "            'CAR_PLATE':'red',\n",
        "            'ORG':'purple',\n",
        "            'NRIC': 'red',\n",
        "            'PASSPORT_NUM':'green'\n",
        "        }\n",
        "\n",
        "        print(\"entities\",entities)\n",
        "        # Replace entities with colored versions\n",
        "        for entity, entity_type in entities:\n",
        "            #print(\"before update data\",data)\n",
        "            color = color_map.get(entity_type, 'blue')  # Default to blue if type not found\n",
        "            colored_entity = f'<span style=\"color: {color};\">{entity} {entity_type}</span>'\n",
        "            data = data.replace(entity, colored_entity)\n",
        "            #print(\"after update data\",data)\n",
        "\n",
        "        return data\n",
        "\n",
        "    def processData(self):\n",
        "        # Transcribe audio and extract entities\n",
        "        try:\n",
        "            # Load audio\n",
        "            audio = whisper.load_audio(self._AudiofileName)\n",
        "            output = whisper.transcribe(self.model, audio, beam_size=5, best_of=5, temperature=(0.0, 0.2, 0.4, 0.6, 0.8, 1.0),vad=True, language=\"en\", remove_punctuation_from_words=True,refine_whisper_precision=0.6,min_word_duration=0.01)\n",
        "            #output = whisper.transcribe(self.model, audio, language=\"en\", task='transcribe', temperature=(0.0, 0.2, 0.4, 0.6, 0.8, 1.0), best_of=5, beam_size=5)\"\"\n",
        "            transcription_text = output['text']\n",
        "            transcription_text = re.sub(r\"\\.(?!\\S)\", \" \", transcription_text)\n",
        "            print(\"~~~~~~~~~~~~~~~~\")\n",
        "            print(transcription_text)\n",
        "\n",
        "            #append text\n",
        "            self._PII_text_and_Timestamp += (transcription_text)+\"\\n\"\n",
        "            # Run NER with spaCy\n",
        "            doc = self.nlp(transcription_text)\n",
        "            entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
        "            uniqueentities = list(set(entities))\n",
        "            entity_counts = self.count_entities(entities)\n",
        "\n",
        "            for entity_type, count in entity_counts.items():\n",
        "                #append to metrics\n",
        "                self._Metrics += (entity_type+ \" : \"+ str(count))+\"\\n\"\n",
        "\n",
        "            transcribeWithEntities = self.colorize_entities(transcription_text, uniqueentities)\n",
        "\n",
        "            #append to transcribeWithEntities\n",
        "            self._Transcribe_Text_With_Entities = transcribeWithEntities\n",
        "\n",
        "            print(f\"Transcription: {transcription_text}\")\n",
        "            print(f\"Entities: {entities}\")\n",
        "\n",
        "            # Beepify audio segments containing PII entities\n",
        "            audio_to_beep = AudioSegment.from_file(self._AudiofileName)\n",
        "\n",
        "            # Process the audio file to beepify words (remaining unchanged)\n",
        "            # Extract segments to be beeped\n",
        "            self.segments_to_beep = []\n",
        "\n",
        "            pii_Text_TimeStamp = []\n",
        "\n",
        "            for ent in doc.ents:\n",
        "                self.segments_to_beep.append((ent.start_char, ent.end_char))\n",
        "                pii_Text_TimeStamp.append((ent.text,ent.start_char*200,ent.end_char*200))\n",
        "                print(\"=======\")\n",
        "                print(\"ent.text\",ent.text)\n",
        "                print(\"ent.start\",ent.start_char)\n",
        "                print(\"ent.end\",ent.end_char)\n",
        "\n",
        "                print(pii_Text_TimeStamp)\n",
        "            for ent in pii_Text_TimeStamp:\n",
        "                self._PII_text_and_Timestamp += (\"Timestamp: \"+str(ent[1]/1000)+ \" --- \"+str(ent[2]/1000)+\" sec\")+\"\\n\"\n",
        "                self._PII_text_and_Timestamp  += (\"Text: \"+ent[0])+\"\\n\"\n",
        "\n",
        "\n",
        "            # Convert character offsets to time (assuming 1 character = 20 ms)\n",
        "            segments_in_ms = [(start*200, end*200) for start, end in self.segments_to_beep]\n",
        "            print(\"Segments:\", segments_in_ms)\n",
        "\n",
        "\n",
        "\n",
        "            words_to_beepify =[]\n",
        "\n",
        "            # append the all text in the doc the words_to_beepify array\n",
        "            for word in doc.ents:\n",
        "                # words_to_beepify.append(word.text)\n",
        "                words_to_beepify.append(word.text.replace('.', ''))\n",
        "\n",
        "            print(words_to_beepify)\n",
        "\n",
        "            # New list to store individual words\n",
        "            individual_words_to_beepify = []\n",
        "\n",
        "            # Split each phrase into individual words and append to the new list\n",
        "            for phrase in words_to_beepify:\n",
        "                individual_words_to_beepify.extend(phrase.split())\n",
        "\n",
        "            # Remove duplicates by converting the list to a set and then back to a list\n",
        "            #individual_words_to_beepify = list(set(individual_words_to_beepify))\n",
        "            individual_words_to_beepify = list(dict.fromkeys(individual_words_to_beepify))\n",
        "\n",
        "            print(individual_words_to_beepify)\n",
        "\n",
        "            # Load the beep sound\n",
        "            beep_sound = AudioSegment.from_file(self._BeepAudiofileName)\n",
        "\n",
        "\n",
        "\n",
        "            # Iterate over the words array in segment array of the output\n",
        "            for segment in output[\"segments\"]:\n",
        "                for word in segment[\"words\"]:\n",
        "\n",
        "                    # Check if the word is in the list of words to beepify\n",
        "                    if word[\"text\"] in individual_words_to_beepify:\n",
        "                        # Get the start and end time of the word\n",
        "                        print(\"*******\")\n",
        "                        print(word)\n",
        "\n",
        "                        start_time = word[\"start\"]\n",
        "                        end_time = word[\"end\"]\n",
        "\n",
        "                        # Get the start and end indices of the word\n",
        "                        start_index = float(start_time * 1000)\n",
        "                        end_index = float(end_time * 1000 + 100) # Add 100ms buffer\n",
        "\n",
        "                        # Calculate the duration of the word segment\n",
        "                        word_duration = (end_index - start_index)\n",
        "                        print(word_duration)\n",
        "                        # Create a silent segment with the same duration as the word\n",
        "                        silent_segment = AudioSegment.silent(duration=word_duration)\n",
        "\n",
        "\n",
        "                        # Replace the word segment with the silent segment in the original audio\n",
        "                        audio_to_beep = audio_to_beep[:int(start_index)] + silent_segment + audio_to_beep[int(end_index):]\n",
        "\n",
        "                        # Get the start and end indices of the beep sound to match the word's duration\n",
        "                        beep_start_index = 0\n",
        "                        beep_end_index = word_duration + 200 # Add 200ms\n",
        "                        #beep_end_index = word_duration\n",
        "\n",
        "\n",
        "                        # Trim the beep sound to match the word's duration\n",
        "                        beep_sound = beep_sound[beep_start_index:beep_end_index]\n",
        "\n",
        "                        \"\"\" if word_duration > len(beep_sound):\n",
        "                            beep_sound = beep_sound + AudioSegment.silent(duration=word_duration - len(beep_sound))\n",
        "                        else:\n",
        "                            beep_sound = beep_sound[:word_duration] \"\"\"\n",
        "\n",
        "                        #Overlay the beep sound on the silent segment\n",
        "                        audio_to_beep = audio_to_beep.overlay(beep_sound, position=int(start_index))\n",
        "\n",
        "            # Save the beeped audio file\n",
        "            # Get formatted date and time\n",
        "            formatted_datetime = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S_\")\n",
        "            random_filename =   str(formatted_datetime) + secure_filename(Path(self._AudiofileName).name)\n",
        "            output_path = os.path.join(\"pii_beep_audio_uploads\", f\"beeped_audio_{random_filename}\")\n",
        "            os.makedirs(\"pii_beep_audio_uploads\", exist_ok=True)\n",
        "\n",
        "\n",
        "            audio_to_beep.export(output_path)\n",
        "            #audio_to_beep.export(output_path, format=\"wav\")\n",
        "            self._BeepedAudiofileName =output_path\n",
        "\n",
        "            print(f\"Beeped audio file saved at: {output_path}\")\n",
        "            self.callback({\n",
        "                \"PII_text_and_Timestamp\": self._Transcribe_Text_With_Entities,\n",
        "                \"Transcribe_Text_With_Entities\": self._PII_text_and_Timestamp,\n",
        "                \"Metrics\": self._Metrics,\n",
        "                \"Beeped_Audio_Path\": self._BeepedAudiofileName\n",
        "            })\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred during transcription: {str(e)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "c0336d64",
      "metadata": {
        "id": "c0336d64"
      },
      "outputs": [],
      "source": [
        "# Callback function for Gradio\n",
        "def start_worker(audio_file_path, model_directory):\n",
        "    result = {\n",
        "        \"PII_text_and_Timestamp\": \"Processing...\",\n",
        "        \"Transcribe_Text_With_Entities\": \"Processing...\",\n",
        "        \"Metrics\": \"Processing...\",\n",
        "        \"Beeped_Audio_Path\": \"beep2.mp3\"\n",
        "    }\n",
        "\n",
        "    def update_result(message):\n",
        "        if isinstance(message, dict):\n",
        "            result.update({\n",
        "                \"PII_text_and_Timestamp\": str(message.get(\"PII_text_and_Timestamp\")),\n",
        "                \"Transcribe_Text_With_Entities\": message.get(\"Transcribe_Text_With_Entities\"),\n",
        "                \"Metrics\":  str(message.get('Metrics')),\n",
        "                \"Beeped_Audio_Path\":  str(message.get('Beeped_Audio_Path'))\n",
        "\n",
        "            })\n",
        "        print(\"Processing complete.\")\n",
        "\n",
        "    if not audio_file_path or os.stat(audio_file_path).st_size == 0:\n",
        "        return gr.update(visible=True), \"Error: No input provided. Please upload a audio file\"\n",
        "\n",
        "    if not model_directory or os.stat(model_directory).st_size == 0:\n",
        "        return gr.update(visible=True), \"Error: No input provided. Please upload model(.zip)file\"\n",
        "\n",
        "\n",
        "    # Start worker in a separate thread\n",
        "    worker = Worker(audio_file_path, model_directory, update_result)\n",
        "    worker.start()\n",
        "\n",
        "    # Wait for the worker to finish\n",
        "    worker.join()\n",
        "\n",
        "    #returning result to called function\n",
        "    return result[\"PII_text_and_Timestamp\"], result[\"Transcribe_Text_With_Entities\"], result[\"Metrics\"], result[\"Beeped_Audio_Path\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "93684046",
      "metadata": {
        "id": "93684046"
      },
      "outputs": [],
      "source": [
        "def reset():\n",
        "    return None, None, None, None, None\n",
        "def get_audio_file_path(audio):\n",
        "    return audio\n",
        "\n",
        "def load_model(files):\n",
        "    if files:\n",
        "        # Assume the uploaded file is a zip file representing the directory\n",
        "        zip_file_path = files.name\n",
        "\n",
        "        # Define a directory to extract the zip\n",
        "        extract_dir = \"extracted_model\"\n",
        "\n",
        "        # Clean the directory if it already exists\n",
        "        if os.path.exists(extract_dir):\n",
        "            shutil.rmtree(extract_dir)\n",
        "\n",
        "        os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "        # Extract the zip file contents\n",
        "        with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(extract_dir)\n",
        "\n",
        "        # Debug output: List the contents of the extracted directory\n",
        "        extracted_files = []\n",
        "        for root, dirs, files in os.walk(extract_dir):\n",
        "            for file in files:\n",
        "                extracted_files.append(os.path.join(root, file))\n",
        "\n",
        "        print(\"Extracted files:\")\n",
        "        for file in extracted_files:\n",
        "            print(file)\n",
        "\n",
        "        # Determine the base directory inside the extracted directory\n",
        "        base_dir = None\n",
        "        for root, dirs, files in os.walk(extract_dir):\n",
        "            if files and 'meta.json' in files:\n",
        "                base_dir = root\n",
        "                break\n",
        "\n",
        "        # Check if meta.json was found and construct the path\n",
        "        if base_dir:\n",
        "            meta_path = os.path.join(base_dir, \"meta.json\")\n",
        "            if os.path.exists(meta_path):\n",
        "                return base_dir\n",
        "            else:\n",
        "                directory_message = \"Invalid model directory: meta.json not found\"\n",
        "        else:\n",
        "            directory_message = \"Invalid model directory: meta.json not found\"\n",
        "\n",
        "    else:\n",
        "        directory_message = \"No directory selected\"\n",
        "\n",
        "    return directory_message"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "0b5ef8f0",
      "metadata": {
        "id": "0b5ef8f0"
      },
      "outputs": [],
      "source": [
        "# Function to load and return the audio file path\n",
        "def load_audio(beep_audio_file_output):\n",
        "    if beep_audio_file_output is not None:\n",
        "        return beep_audio_file_output.name  # Return the path to the uploaded file\n",
        "    return None\n",
        "\n",
        "# Function to enable the button based on the text input status\n",
        "def check_texts(audio_output, model_output_path):\n",
        "    return gr.update(interactive=bool(audio_output and model_output_path))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "7c972f15",
      "metadata": {
        "id": "7c972f15"
      },
      "outputs": [],
      "source": [
        "# Gradio UI\n",
        "with gr.Blocks(css=\"\"\"\n",
        "    .centered {\n",
        "        display: flex;\n",
        "        justify-content: center;\n",
        "        align-items: center;    }\n",
        "\n",
        "        .custom-label {\n",
        "            font-size: 14px;\n",
        "            font-weight: bold;\n",
        "            text-align: left;\n",
        "            height: 100px;\n",
        "            border: 0px solid black;\n",
        "        }\n",
        "\"\"\") as demo:\n",
        "\n",
        "    gr.Markdown(\"# Speech De-Identification Framework ver-3.0\", elem_classes=\"centered\")\n",
        "\n",
        "    with gr.Column():\n",
        "\n",
        "        with gr.Row():\n",
        "\n",
        "            audio_input = gr.Audio(label=\"Upload Audio File\", type=\"filepath\")\n",
        "            audio_output = gr.Textbox(label=\"Audio File Path\", interactive=False, visible = False)\n",
        "            audio_input.change(fn=get_audio_file_path, inputs=audio_input, outputs=audio_output)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Model directory input (as a zip file)\n",
        "            model_dir_input = gr.File(label=\"Select ML Model as zip file\", file_count=\"single\")\n",
        "            model_output_path = gr.Textbox(label=\"Model Load Status\", interactive=False, visible = False)\n",
        "            model_dir_input.change(fn=load_model, inputs=model_dir_input, outputs=model_output_path)\n",
        "\n",
        "\n",
        "\n",
        "        with gr.Row():\n",
        "            gr.Markdown(\"\")\n",
        "            gr.Markdown(\"\")\n",
        "            gr.Markdown(\"\")\n",
        "            gr.Markdown(\"\")\n",
        "            gr.Markdown(\"\")\n",
        "\n",
        "            reset_button = gr.Button(\"Reset\")\n",
        "            submit_button = gr.Button(\"Submit\",interactive = False)\n",
        "\n",
        "\n",
        "        #enable or dsiable submit button based on file upload status\n",
        "        audio_output.change(check_texts, inputs=[audio_output, model_output_path], outputs=submit_button)\n",
        "        model_output_path.change(check_texts, inputs=[audio_output, model_output_path], outputs=submit_button)\n",
        "\n",
        "\n",
        "\n",
        "        gr.Markdown(\"### Transcribe Text and Entities:\")\n",
        "        pii_text_output = RichTextbox(show_label=False , interactive=False)\n",
        "        gr.Markdown(\"### PII Text and Time Stamps:\")\n",
        "        transcribe_text_output = gr.Textbox(show_label=False , interactive=False)\n",
        "        gr.Markdown(\"### Metrics:\")\n",
        "        metrics_output = gr.Textbox(show_label=False , interactive=False)\n",
        "\n",
        "        with gr.Row():\n",
        "            # Audio component to display the audio file in the interface\n",
        "            beep_audio_file_output = gr.File(label=\"Download Beeped Audio\", interactive=False)\n",
        "\n",
        "            # Audio player component to play the selected audio file\n",
        "            audio_player = gr.Audio(label=\"Play Beeped Audio\", type=\"filepath\")\n",
        "\n",
        "            # Automatically update the audio player when the file component changes\n",
        "            beep_audio_file_output.change(load_audio, inputs=beep_audio_file_output, outputs=audio_player)\n",
        "\n",
        "\n",
        "    # Event Handlers\n",
        "    reset_button.click(reset, [], [audio_input, model_dir_input, pii_text_output, transcribe_text_output, metrics_output])\n",
        "    submit_button.click(start_worker, [audio_output, model_output_path], [pii_text_output, transcribe_text_output, metrics_output,beep_audio_file_output])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9ecc4f6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "e9ecc4f6",
        "outputId": "66ef53d6-2ec3-4e13-b8f8-f9ba9ea192ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://308d8b85c78cd4bdd2.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://308d8b85c78cd4bdd2.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted files:\n",
            "extracted_model/tokenizer\n",
            "extracted_model/meta.json\n",
            "extracted_model/config.cfg\n",
            "extracted_model/ner/model\n",
            "extracted_model/ner/moves\n",
            "extracted_model/ner/cfg\n",
            "extracted_model/vocab/strings.json\n",
            "extracted_model/vocab/vectors\n",
            "extracted_model/vocab/key2row\n",
            "extracted_model/vocab/vectors.cfg\n",
            "extracted_model/vocab/lookups.bin\n",
            "Audio File: /tmp/gradio/9321a610a425cfb071ffa50e8f387dca3bf8439e6b0af1c875fc2d1c519519ab/TEST_11.wav\n",
            "Model Directory: extracted_model\n",
            "Beep Audio File: /content/drive/MyDrive/Colab Notebooks/beep2.mp3\n",
            "loading SpaCy model with custom model  extracted_model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_pipeline' (0.0.0) was trained with spaCy v3.7.6 and may not be 100% compatible with the current version (3.7.5). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SpaCy model loaded.\n",
            "cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████████████████████████████████| 1.42G/1.42G [00:11<00:00, 135MiB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:146: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Whisper model loaded.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/hub.py:295: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
            "  warnings.warn(\n",
            "Downloading: \"https://github.com/snakers4/silero-vad/zipball/master\" to /root/.cache/torch/hub/master.zip\n",
            "100%|██████████| 2371/2371 [00:04<00:00, 499.83frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "~~~~~~~~~~~~~~~~\n",
            " Mr  Hong has two credit cards, one in with Master and another one is Visa  The card number is 4578146088604138  Maybe my POSB bank account or DBS is 882861725, not sure \n",
            "entities [('Visa', 'ORG'), ('POSB', 'ORG'), ('DBS', 'ORG'), ('Master', 'ORG'), ('4578146088604138', 'EMAIL'), ('882861725', 'PHONE'), ('two', 'CARDINAL')]\n",
            "Transcription:  Mr  Hong has two credit cards, one in with Master and another one is Visa  The card number is 4578146088604138  Maybe my POSB bank account or DBS is 882861725, not sure \n",
            "Entities: [('two', 'CARDINAL'), ('Master', 'ORG'), ('Visa', 'ORG'), ('4578146088604138', 'EMAIL'), ('POSB', 'ORG'), ('DBS', 'ORG'), ('882861725', 'PHONE')]\n",
            "=======\n",
            "ent.text two\n",
            "ent.start 14\n",
            "ent.end 17\n",
            "[('two', 2800, 3400)]\n",
            "=======\n",
            "ent.text Master\n",
            "ent.start 44\n",
            "ent.end 50\n",
            "[('two', 2800, 3400), ('Master', 8800, 10000)]\n",
            "=======\n",
            "ent.text Visa\n",
            "ent.start 70\n",
            "ent.end 74\n",
            "[('two', 2800, 3400), ('Master', 8800, 10000), ('Visa', 14000, 14800)]\n",
            "=======\n",
            "ent.text 4578146088604138\n",
            "ent.start 95\n",
            "ent.end 111\n",
            "[('two', 2800, 3400), ('Master', 8800, 10000), ('Visa', 14000, 14800), ('4578146088604138', 19000, 22200)]\n",
            "=======\n",
            "ent.text POSB\n",
            "ent.start 122\n",
            "ent.end 126\n",
            "[('two', 2800, 3400), ('Master', 8800, 10000), ('Visa', 14000, 14800), ('4578146088604138', 19000, 22200), ('POSB', 24400, 25200)]\n",
            "=======\n",
            "ent.text DBS\n",
            "ent.start 143\n",
            "ent.end 146\n",
            "[('two', 2800, 3400), ('Master', 8800, 10000), ('Visa', 14000, 14800), ('4578146088604138', 19000, 22200), ('POSB', 24400, 25200), ('DBS', 28600, 29200)]\n",
            "=======\n",
            "ent.text 882861725\n",
            "ent.start 150\n",
            "ent.end 159\n",
            "[('two', 2800, 3400), ('Master', 8800, 10000), ('Visa', 14000, 14800), ('4578146088604138', 19000, 22200), ('POSB', 24400, 25200), ('DBS', 28600, 29200), ('882861725', 30000, 31800)]\n",
            "Segments: [(2800, 3400), (8800, 10000), (14000, 14800), (19000, 22200), (24400, 25200), (28600, 29200), (30000, 31800)]\n",
            "['two', 'Master', 'Visa', '4578146088604138', 'POSB', 'DBS', '882861725']\n",
            "['two', 'Master', 'Visa', '4578146088604138', 'POSB', 'DBS', '882861725']\n",
            "*******\n",
            "{'text': 'two', 'start': 1.3, 'end': 1.74, 'confidence': 0.894}\n",
            "540.0\n",
            "*******\n",
            "{'text': 'Master', 'start': 3.52, 'end': 3.96, 'confidence': 0.563}\n",
            "540.0\n",
            "*******\n",
            "{'text': 'Visa', 'start': 5.54, 'end': 5.88, 'confidence': 0.842}\n",
            "440.0\n",
            "*******\n",
            "{'text': '4578146088604138', 'start': 7.36, 'end': 15.42, 'confidence': 0.863}\n",
            "8160.0\n",
            "*******\n",
            "{'text': 'POSB', 'start': 16.3, 'end': 16.98, 'confidence': 0.954}\n",
            "780.0\n",
            "*******\n",
            "{'text': 'DBS', 'start': 17.88, 'end': 18.3, 'confidence': 0.956}\n",
            "520.0\n",
            "*******\n",
            "{'text': '882861725', 'start': 18.98, 'end': 22.74, 'confidence': 0.678}\n",
            "3860.0\n",
            "Beeped audio file saved at: pii_beep_audio_uploads/beeped_audio_2024_10_15_03_32_52_TEST_11.wav\n",
            "Processing complete.\n",
            "Processing complete.\n"
          ]
        }
      ],
      "source": [
        "demo.launch(inbrowser=True, show_error=True,share = True,debug=True )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fQpL7HVpCDVQ",
      "metadata": {
        "id": "fQpL7HVpCDVQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "257960a9-624a-4c8c-89e9-5822827d8962"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/Pipeline/NER\n"
          ]
        }
      ],
      "source": [
        "#!pip freeze > requirements.txt\n",
        "!pwd"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}