{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "164bc945",
      "metadata": {
        "id": "164bc945"
      },
      "source": [
        "**This Gradio app version 4 updated on 15th Oct 2024.**\n",
        "\n",
        "*   Please change beep sound wave filepath according to your local dir in **\"Beeped_Audio_Path\": line 254**\n",
        "\n",
        "*  change the whisper model  at **whisper.load_model** (medium/large/small)\n",
        "* Whisper version should be Nov 06, 2023 version. **pip install openai-whisper==20231106**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sRHc1I7TNzMy",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRHc1I7TNzMy",
        "outputId": "3367d977-7f90-46b7-faf9-524486f7f114"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HzTp9DsACO3R",
      "metadata": {
        "id": "HzTp9DsACO3R"
      },
      "source": [
        "**Other Notes:**\n",
        "\n",
        "*   Input audio: TEST_9.mp3,TEST_10.wav,TEST_11.mp3\n",
        "*   Spacy transformer based Models\n",
        "1.   Final_augmented_data_base_sim_0.6_trf.zip or\n",
        "2.   Final_augmented_data_base_sim_0.3_trf.zip\n",
        "* output file stored in **pii_beep_audio_uploads**\n",
        "For example, *new_1083801646TEST_11.wav* for TEST_11.mp3\n",
        "\n",
        "**Code changelog**\n",
        "1.   Minor change in whisper.transcribe function parameters\n",
        "2.   Removed the fullstop [.] or comma [.] on the transcription_text except\n",
        "     email on line 83. It improves the accuracy of the detection\n",
        "\n",
        "\n",
        "3.   The Submit button enables **only when Audio file /Model loaded**.otherwise it is disabled.\n",
        "4.   Output Beeped Audio will have Timestamp like\n",
        "    **beeped_audio_2024_10_14_02_15_21_TEST_10**.wav\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "G0ykfmgzR4Qz",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0ykfmgzR4Qz",
        "outputId": "d4f25138-cfde-4f68-c1f6-6b3bce06b065"
      },
      "outputs": [],
      "source": [
        "#@markdown **GPU check and Python version check** (you typically atleast A100 GPU)\n",
        "!nvidia-smi -L\n",
        "#!nvidia-smi\n",
        "!python3 --version\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1FYUMVyzayLI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FYUMVyzayLI",
        "outputId": "3c84700d-09af-424b-fd05-284e25498058"
      },
      "outputs": [],
      "source": [
        "#@markdown **Google Drive mount**\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8uISykMPa7SS",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uISykMPa7SS",
        "outputId": "a72ca8ce-90f2-4368-c157-8afcf013cb6f"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/Colab Notebooks/Pipeline/NER')\n",
        "print(\"Current directory:\", os.getcwd())\n",
        "directory = '/content/drive/MyDrive/Colab Notebooks/Pipeline/NER'\n",
        "filename = '/content/drive/MyDrive/Colab Notebooks/beep2.mp3'\n",
        "BeepAudiofileName = os.path.join(directory, filename)\n",
        "print(\"Beep Audio File path:\", BeepAudiofileName)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Tpr50MAAmKAe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tpr50MAAmKAe",
        "outputId": "26a34e3d-60ac-400b-8296-add2d189fa3b"
      },
      "outputs": [],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "D_xFfApha_po",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_xFfApha_po",
        "outputId": "f1c3154a-1162-4234-ecbd-e23985e7ec78"
      },
      "outputs": [],
      "source": [
        "# ! and % command similar function. % handles well if multiple version of a library is detected in the system\n",
        "#%pip uninstall openai-whisper -y\n",
        "#%pip install gradio\n",
        "\n",
        "!pip install openai-whisper==20231106\n",
        "!sudo apt install python3-pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DhBolyOk9ldp",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhBolyOk9ldp",
        "outputId": "6db464d8-3d1f-4ac1-cd0b-9fa8c7b22e9c"
      },
      "outputs": [],
      "source": [
        "import whisper\n",
        "print(whisper.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AvQsChUNzcQp",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvQsChUNzcQp",
        "outputId": "39e4b88c-45ad-4cf4-f6b3-2babf2c661d9"
      },
      "outputs": [],
      "source": [
        "# To avoid the WARNING:whisper_timestamped:Please install onnxruntime to use more efficiently silero VAD\n",
        "!pip install silero-vad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AsyqNfMjO_Ih",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsyqNfMjO_Ih",
        "outputId": "37db8c00-dfcf-4426-9dc9-be43166b56c0"
      },
      "outputs": [],
      "source": [
        "!sudo apt update && sudo apt install ffmpeg\n",
        "!sudo pip3 install setuptools-rust\n",
        "%pip install openai\n",
        "%pip install openai-whisper\n",
        "%pip install whisper-timestamped\n",
        "%pip install gradio\n",
        "!pip install gradio-rich-textbox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88667037",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88667037",
        "outputId": "03474007-13a6-4b9c-851d-a0ef1c80f47b"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import os\n",
        "import random\n",
        "import whisper_timestamped as whisper\n",
        "from pydub import AudioSegment\n",
        "import numpy as np\n",
        "import spacy\n",
        "import torch\n",
        "import threading\n",
        "import zipfile\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "from werkzeug.utils import secure_filename\n",
        "import time\n",
        "from gradio_rich_textbox import RichTextbox\n",
        "import re\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "12a198ed",
      "metadata": {
        "id": "12a198ed"
      },
      "outputs": [],
      "source": [
        "# Worker class to process the audio file and load models\n",
        "class Worker(threading.Thread):\n",
        "    def __init__(self, audio_file_path, model_directory, callback):\n",
        "        threading.Thread.__init__(self)\n",
        "        self._AudiofileName = audio_file_path\n",
        "        self._ModelDirectory = model_directory\n",
        "        #self._BeepAudiofileName = \"beep2.mp3\"\n",
        "        self._BeepAudiofileName = BeepAudiofileName\n",
        "        self.callback = callback\n",
        "\n",
        "        self._PII_text_and_Timestamp =\"\"\n",
        "        self._Transcribe_Text_With_Entities =\"\"\n",
        "        self._Metrics =\"\"\n",
        "        self._BeepedAudiofileName =\"\"\n",
        "\n",
        "        print(f\"Audio File: {self._AudiofileName}\")\n",
        "        print(f\"Model Directory: {self._ModelDirectory}\")\n",
        "        print(f\"Beep Audio File: {self._BeepAudiofileName}\")\n",
        "\n",
        "    def run(self):\n",
        "        try:\n",
        "            print(\"loading SpaCy model with custom model \",str(self._ModelDirectory))\n",
        "            # Load spaCy model from directory or a known model name\n",
        "            self.nlp = spacy.load(str(self._ModelDirectory))\n",
        "            print(\"SpaCy model loaded.\")\n",
        "\n",
        "            # Load Whisper model\n",
        "            devices = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "            print(devices)\n",
        "            time.sleep(0.2)\n",
        "            self.model = whisper.load_model(\"medium\", device=devices)\n",
        "\n",
        "            print(\"Whisper model loaded.\")\n",
        "\n",
        "            self.processData()\n",
        "            self.callback(\"callback Processing complete!\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error during processing: {str(e)}\")\n",
        "\n",
        "    def count_entities(self,entities):\n",
        "        entity_counts = {}  # Initialize an empty dictionary to store counts\n",
        "\n",
        "        for _, entity_type in entities:\n",
        "            # Increment the count for each entity type\n",
        "            entity_counts[entity_type] = entity_counts.get(entity_type, 0) + 1\n",
        "\n",
        "        return entity_counts\n",
        "\n",
        "    def colorize_entities(self, data, entities):\n",
        "        # Define color mappings (you can customize these)\n",
        "        color_map = {\n",
        "            'PERSON': 'blue',\n",
        "            'GPE': 'green',\n",
        "            'LOC': 'purple',\n",
        "            'PHONE': 'orange',\n",
        "            'EMAIL': 'blue',\n",
        "            'CAR_PLATE':'red',\n",
        "            'ORG':'purple',\n",
        "            'NRIC': 'red',\n",
        "            'PASSPORT_NUM':'green'\n",
        "        }\n",
        "\n",
        "        print(\"entities\",entities)\n",
        "        # Replace entities with colored versions\n",
        "        for entity, entity_type in entities:\n",
        "            #print(\"before update data\",data)\n",
        "            color = color_map.get(entity_type, 'blue')  # Default to blue if type not found\n",
        "            colored_entity = f'<span style=\"color: {color};\">{entity} {entity_type}</span>'\n",
        "            data = data.replace(entity, colored_entity)\n",
        "            #print(\"after update data\",data)\n",
        "\n",
        "        return data\n",
        "\n",
        "    def processData(self):\n",
        "        # Transcribe audio and extract entities\n",
        "        try:\n",
        "            # Load audio\n",
        "            audio = whisper.load_audio(self._AudiofileName)\n",
        "            output = whisper.transcribe(self.model, audio, beam_size=5, best_of=5, temperature=(0.0, 0.2, 0.4, 0.6, 0.8, 1.0),vad=True, language=\"en\", remove_punctuation_from_words=True,refine_whisper_precision=0.6,min_word_duration=0.01)\n",
        "            #output = whisper.transcribe(self.model, audio, language=\"en\", task='transcribe', temperature=(0.0, 0.2, 0.4, 0.6, 0.8, 1.0), best_of=5, beam_size=5)\"\"\n",
        "            transcription_text = output['text']\n",
        "            transcription_text = re.sub(r\"\\.(?!\\S)\", \" \", transcription_text)\n",
        "            print(\"~~~~~~~~~~~~~~~~\")\n",
        "            print(transcription_text)\n",
        "\n",
        "            #append text\n",
        "            self._PII_text_and_Timestamp += (transcription_text)+\"\\n\"\n",
        "            # Run NER with spaCy\n",
        "            doc = self.nlp(transcription_text)\n",
        "            entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
        "            uniqueentities = list(set(entities))\n",
        "            entity_counts = self.count_entities(entities)\n",
        "\n",
        "            for entity_type, count in entity_counts.items():\n",
        "                #append to metrics\n",
        "                self._Metrics += (entity_type+ \" : \"+ str(count))+\"\\n\"\n",
        "\n",
        "            transcribeWithEntities = self.colorize_entities(transcription_text, uniqueentities)\n",
        "\n",
        "            #append to transcribeWithEntities\n",
        "            self._Transcribe_Text_With_Entities = transcribeWithEntities\n",
        "\n",
        "            print(f\"Transcription: {transcription_text}\")\n",
        "            print(f\"Entities: {entities}\")\n",
        "\n",
        "            # Beepify audio segments containing PII entities\n",
        "            audio_to_beep = AudioSegment.from_file(self._AudiofileName)\n",
        "\n",
        "            # Process the audio file to beepify words (remaining unchanged)\n",
        "            # Extract segments to be beeped\n",
        "            self.segments_to_beep = []\n",
        "\n",
        "            pii_Text_TimeStamp = []\n",
        "\n",
        "            for ent in doc.ents:\n",
        "                self.segments_to_beep.append((ent.start_char, ent.end_char))\n",
        "                pii_Text_TimeStamp.append((ent.text,ent.start_char*200,ent.end_char*200))\n",
        "                print(\"=======\")\n",
        "                print(\"ent.text\",ent.text)\n",
        "                print(\"ent.start\",ent.start_char)\n",
        "                print(\"ent.end\",ent.end_char)\n",
        "\n",
        "                print(pii_Text_TimeStamp)\n",
        "            for ent in pii_Text_TimeStamp:\n",
        "                self._PII_text_and_Timestamp += (\"Timestamp: \"+str(ent[1]/1000)+ \" --- \"+str(ent[2]/1000)+\" sec\")+\"\\n\"\n",
        "                self._PII_text_and_Timestamp  += (\"Text: \"+ent[0])+\"\\n\"\n",
        "\n",
        "\n",
        "            # Convert character offsets to time (assuming 1 character = 20 ms)\n",
        "            segments_in_ms = [(start*200, end*200) for start, end in self.segments_to_beep]\n",
        "            print(\"Segments:\", segments_in_ms)\n",
        "\n",
        "\n",
        "\n",
        "            words_to_beepify =[]\n",
        "\n",
        "            # append the all text in the doc the words_to_beepify array\n",
        "            for word in doc.ents:\n",
        "                # words_to_beepify.append(word.text)\n",
        "                words_to_beepify.append(word.text.replace('.', ''))\n",
        "\n",
        "            print(words_to_beepify)\n",
        "\n",
        "            # New list to store individual words\n",
        "            individual_words_to_beepify = []\n",
        "\n",
        "            # Split each phrase into individual words and append to the new list\n",
        "            for phrase in words_to_beepify:\n",
        "                individual_words_to_beepify.extend(phrase.split())\n",
        "\n",
        "            # Remove duplicates by converting the list to a set and then back to a list\n",
        "            #individual_words_to_beepify = list(set(individual_words_to_beepify))\n",
        "            individual_words_to_beepify = list(dict.fromkeys(individual_words_to_beepify))\n",
        "\n",
        "            print(individual_words_to_beepify)\n",
        "\n",
        "            # Load the beep sound\n",
        "            beep_sound = AudioSegment.from_file(self._BeepAudiofileName)\n",
        "\n",
        "\n",
        "\n",
        "            # Iterate over the words array in segment array of the output\n",
        "            for segment in output[\"segments\"]:\n",
        "                for word in segment[\"words\"]:\n",
        "\n",
        "                    # Check if the word is in the list of words to beepify\n",
        "                    if word[\"text\"] in individual_words_to_beepify:\n",
        "                        # Get the start and end time of the word\n",
        "                        print(\"*******\")\n",
        "                        print(word)\n",
        "\n",
        "                        start_time = word[\"start\"]\n",
        "                        end_time = word[\"end\"]\n",
        "\n",
        "                        # Get the start and end indices of the word\n",
        "                        start_index = float(start_time * 1000)\n",
        "                        end_index = float(end_time * 1000 + 100) # Add 100ms buffer\n",
        "\n",
        "                        # Calculate the duration of the word segment\n",
        "                        word_duration = (end_index - start_index)\n",
        "                        print(word_duration)\n",
        "                        # Create a silent segment with the same duration as the word\n",
        "                        silent_segment = AudioSegment.silent(duration=word_duration)\n",
        "\n",
        "\n",
        "                        # Replace the word segment with the silent segment in the original audio\n",
        "                        audio_to_beep = audio_to_beep[:int(start_index)] + silent_segment + audio_to_beep[int(end_index):]\n",
        "\n",
        "                        # Get the start and end indices of the beep sound to match the word's duration\n",
        "                        beep_start_index = 0\n",
        "                        beep_end_index = word_duration + 200 # Add 200ms\n",
        "                        #beep_end_index = word_duration\n",
        "\n",
        "\n",
        "                        # Trim the beep sound to match the word's duration\n",
        "                        beep_sound = beep_sound[beep_start_index:beep_end_index]\n",
        "\n",
        "                        \"\"\" if word_duration > len(beep_sound):\n",
        "                            beep_sound = beep_sound + AudioSegment.silent(duration=word_duration - len(beep_sound))\n",
        "                        else:\n",
        "                            beep_sound = beep_sound[:word_duration] \"\"\"\n",
        "\n",
        "                        #Overlay the beep sound on the silent segment\n",
        "                        audio_to_beep = audio_to_beep.overlay(beep_sound, position=int(start_index))\n",
        "\n",
        "            # Save the beeped audio file\n",
        "            # Get formatted date and time\n",
        "            formatted_datetime = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S_\")\n",
        "            random_filename =   str(formatted_datetime) + secure_filename(Path(self._AudiofileName).name)\n",
        "            output_path = os.path.join(\"pii_beep_audio_uploads\", f\"beeped_audio_{random_filename}\")\n",
        "            os.makedirs(\"pii_beep_audio_uploads\", exist_ok=True)\n",
        "\n",
        "\n",
        "            audio_to_beep.export(output_path)\n",
        "            #audio_to_beep.export(output_path, format=\"wav\")\n",
        "            self._BeepedAudiofileName =output_path\n",
        "\n",
        "            print(f\"Beeped audio file saved at: {output_path}\")\n",
        "            self.callback({\n",
        "                \"PII_text_and_Timestamp\": self._Transcribe_Text_With_Entities,\n",
        "                \"Transcribe_Text_With_Entities\": self._PII_text_and_Timestamp,\n",
        "                \"Metrics\": self._Metrics,\n",
        "                \"Beeped_Audio_Path\": self._BeepedAudiofileName\n",
        "            })\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred during transcription: {str(e)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "c0336d64",
      "metadata": {
        "id": "c0336d64"
      },
      "outputs": [],
      "source": [
        "# Callback function for Gradio\n",
        "def start_worker(audio_file_path, model_directory):\n",
        "    result = {\n",
        "        \"PII_text_and_Timestamp\": \"Processing...\",\n",
        "        \"Transcribe_Text_With_Entities\": \"Processing...\",\n",
        "        \"Metrics\": \"Processing...\",\n",
        "        \"Beeped_Audio_Path\": \"beep2.mp3\"\n",
        "    }\n",
        "\n",
        "    def update_result(message):\n",
        "        if isinstance(message, dict):\n",
        "            result.update({\n",
        "                \"PII_text_and_Timestamp\": str(message.get(\"PII_text_and_Timestamp\")),\n",
        "                \"Transcribe_Text_With_Entities\": message.get(\"Transcribe_Text_With_Entities\"),\n",
        "                \"Metrics\":  str(message.get('Metrics')),\n",
        "                \"Beeped_Audio_Path\":  str(message.get('Beeped_Audio_Path'))\n",
        "\n",
        "            })\n",
        "        print(\"Processing complete.\")\n",
        "\n",
        "    if not audio_file_path or os.stat(audio_file_path).st_size == 0:\n",
        "        return gr.update(visible=True), \"Error: No input provided. Please upload a audio file\"\n",
        "\n",
        "    if not model_directory or os.stat(model_directory).st_size == 0:\n",
        "        return gr.update(visible=True), \"Error: No input provided. Please upload model(.zip)file\"\n",
        "\n",
        "\n",
        "    # Start worker in a separate thread\n",
        "    worker = Worker(audio_file_path, model_directory, update_result)\n",
        "    worker.start()\n",
        "\n",
        "    # Wait for the worker to finish\n",
        "    worker.join()\n",
        "\n",
        "    #returning result to called function\n",
        "    return result[\"PII_text_and_Timestamp\"], result[\"Transcribe_Text_With_Entities\"], result[\"Metrics\"], result[\"Beeped_Audio_Path\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "93684046",
      "metadata": {
        "id": "93684046"
      },
      "outputs": [],
      "source": [
        "def reset():\n",
        "    return None, None, None, None, None\n",
        "def get_audio_file_path(audio):\n",
        "    return audio\n",
        "\n",
        "def load_model(files):\n",
        "    if files:\n",
        "        # Assume the uploaded file is a zip file representing the directory\n",
        "        zip_file_path = files.name\n",
        "\n",
        "        # Define a directory to extract the zip\n",
        "        extract_dir = \"extracted_model\"\n",
        "\n",
        "        # Clean the directory if it already exists\n",
        "        if os.path.exists(extract_dir):\n",
        "            shutil.rmtree(extract_dir)\n",
        "\n",
        "        os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "        # Extract the zip file contents\n",
        "        with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(extract_dir)\n",
        "\n",
        "        # Debug output: List the contents of the extracted directory\n",
        "        extracted_files = []\n",
        "        for root, dirs, files in os.walk(extract_dir):\n",
        "            for file in files:\n",
        "                extracted_files.append(os.path.join(root, file))\n",
        "\n",
        "        print(\"Extracted files:\")\n",
        "        for file in extracted_files:\n",
        "            print(file)\n",
        "\n",
        "        # Determine the base directory inside the extracted directory\n",
        "        base_dir = None\n",
        "        for root, dirs, files in os.walk(extract_dir):\n",
        "            if files and 'meta.json' in files:\n",
        "                base_dir = root\n",
        "                break\n",
        "\n",
        "        # Check if meta.json was found and construct the path\n",
        "        if base_dir:\n",
        "            meta_path = os.path.join(base_dir, \"meta.json\")\n",
        "            if os.path.exists(meta_path):\n",
        "                return base_dir\n",
        "            else:\n",
        "                directory_message = \"Invalid model directory: meta.json not found\"\n",
        "        else:\n",
        "            directory_message = \"Invalid model directory: meta.json not found\"\n",
        "\n",
        "    else:\n",
        "        directory_message = \"No directory selected\"\n",
        "\n",
        "    return directory_message"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "0b5ef8f0",
      "metadata": {
        "id": "0b5ef8f0"
      },
      "outputs": [],
      "source": [
        "# Function to load and return the audio file path\n",
        "def load_audio(beep_audio_file_output):\n",
        "    if beep_audio_file_output is not None:\n",
        "        return beep_audio_file_output.name  # Return the path to the uploaded file\n",
        "    return None\n",
        "\n",
        "# Function to enable the button based on the text input status\n",
        "def check_texts(audio_output, model_output_path):\n",
        "    return gr.update(interactive=bool(audio_output and model_output_path))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "7c972f15",
      "metadata": {
        "id": "7c972f15"
      },
      "outputs": [],
      "source": [
        "# Gradio UI\n",
        "with gr.Blocks(css=\"\"\"\n",
        "    .centered {\n",
        "        display: flex;\n",
        "        justify-content: center;\n",
        "        align-items: center;    }\n",
        "\n",
        "        .custom-label {\n",
        "            font-size: 14px;\n",
        "            font-weight: bold;\n",
        "            text-align: left;\n",
        "            height: 100px;\n",
        "            border: 0px solid black;\n",
        "        }\n",
        "\"\"\") as demo:\n",
        "\n",
        "    gr.Markdown(\"# Speech De-Identification Framework ver-3.0\", elem_classes=\"centered\")\n",
        "\n",
        "    with gr.Column():\n",
        "\n",
        "        with gr.Row():\n",
        "\n",
        "            audio_input = gr.Audio(label=\"Upload Audio File\", type=\"filepath\")\n",
        "            audio_output = gr.Textbox(label=\"Audio File Path\", interactive=False, visible = False)\n",
        "            audio_input.change(fn=get_audio_file_path, inputs=audio_input, outputs=audio_output)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Model directory input (as a zip file)\n",
        "            model_dir_input = gr.File(label=\"Select ML Model as zip file\", file_count=\"single\")\n",
        "            model_output_path = gr.Textbox(label=\"Model Load Status\", interactive=False, visible = False)\n",
        "            model_dir_input.change(fn=load_model, inputs=model_dir_input, outputs=model_output_path)\n",
        "\n",
        "\n",
        "\n",
        "        with gr.Row():\n",
        "            gr.Markdown(\"\")\n",
        "            gr.Markdown(\"\")\n",
        "            gr.Markdown(\"\")\n",
        "            gr.Markdown(\"\")\n",
        "            gr.Markdown(\"\")\n",
        "\n",
        "            reset_button = gr.Button(\"Reset\")\n",
        "            submit_button = gr.Button(\"Submit\",interactive = False)\n",
        "\n",
        "\n",
        "        #enable or dsiable submit button based on file upload status\n",
        "        audio_output.change(check_texts, inputs=[audio_output, model_output_path], outputs=submit_button)\n",
        "        model_output_path.change(check_texts, inputs=[audio_output, model_output_path], outputs=submit_button)\n",
        "\n",
        "\n",
        "\n",
        "        gr.Markdown(\"### Transcribe Text and Entities:\")\n",
        "        pii_text_output = RichTextbox(show_label=False , interactive=False)\n",
        "        gr.Markdown(\"### PII Text and Time Stamps:\")\n",
        "        transcribe_text_output = gr.Textbox(show_label=False , interactive=False)\n",
        "        gr.Markdown(\"### Metrics:\")\n",
        "        metrics_output = gr.Textbox(show_label=False , interactive=False)\n",
        "\n",
        "        with gr.Row():\n",
        "            # Audio component to display the audio file in the interface\n",
        "            beep_audio_file_output = gr.File(label=\"Download Beeped Audio\", interactive=False)\n",
        "\n",
        "            # Audio player component to play the selected audio file\n",
        "            audio_player = gr.Audio(label=\"Play Beeped Audio\", type=\"filepath\")\n",
        "\n",
        "            # Automatically update the audio player when the file component changes\n",
        "            beep_audio_file_output.change(load_audio, inputs=beep_audio_file_output, outputs=audio_player)\n",
        "\n",
        "\n",
        "    # Event Handlers\n",
        "    reset_button.click(reset, [], [audio_input, model_dir_input, pii_text_output, transcribe_text_output, metrics_output])\n",
        "    submit_button.click(start_worker, [audio_output, model_output_path], [pii_text_output, transcribe_text_output, metrics_output,beep_audio_file_output])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9ecc4f6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "e9ecc4f6",
        "outputId": "66ef53d6-2ec3-4e13-b8f8-f9ba9ea192ed"
      },
      "outputs": [],
      "source": [
        "demo.launch(inbrowser=True, show_error=True,share = True,debug=True )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fQpL7HVpCDVQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQpL7HVpCDVQ",
        "outputId": "257960a9-624a-4c8c-89e9-5822827d8962"
      },
      "outputs": [],
      "source": [
        "#!pip freeze > requirements.txt\n",
        "!pwd"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
